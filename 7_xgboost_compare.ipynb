{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import json\n",
    "import yaml\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from vit_foundry.perceiver import Perceiver, PerceiverConfig\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import collections\n",
    "import shutil\n",
    "from util_xgb import xgb_process_data, xgb_train_and_infer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run = 'lr2e-06_cl32_cscscscscscscscsssss_NEE_lhid64_iemb64_nf10_causal_aux-0.2_drop0.3_ws_v3_MILA'\n",
    "checkpoint = 'checkpoint-12.pth'\n",
    "\n",
    "DATA_DIR = Path(os.path.join('batch', 'data', 'processed', 'v3'))\n",
    "ALL_RUN_DIR = Path('batch/runs')\n",
    "RUN_DIR = ALL_RUN_DIR / Path(run)\n",
    "with open(RUN_DIR / Path('train_sites.txt'), 'r') as f:\n",
    "    TRAIN_SITES = f.read().split('\\n')\n",
    "with open(RUN_DIR / Path('val_sites.txt'), 'r') as f:\n",
    "    VAL_SITES = f.read().split('\\n')\n",
    "CHECKPOINT_PATH = RUN_DIR / Path(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize how many of each site type were in each set\n",
    "def site_configuration():\n",
    "    site_meta = pd.read_csv('processed_site_meta.csv')\n",
    "    igbp_values = list(site_meta['IGBP'].unique())\n",
    "    train_val_igbp = {i: [0,0] for i in igbp_values}\n",
    "    for site in TRAIN_SITES:\n",
    "        igbp = site_meta.loc[site_meta['SITE_ID'] == site, 'IGBP'].values[0]\n",
    "        train_val_igbp[igbp][0] += 1\n",
    "    for site in VAL_SITES:\n",
    "        igbp = site_meta.loc[site_meta['SITE_ID'] == site, 'IGBP'].values[0]\n",
    "        train_val_igbp[igbp][1] += 1\n",
    "\n",
    "    site_type_distribution = pd.DataFrame(data=train_val_igbp).T.rename(columns={0: 'train', 1: 'val'})\n",
    "    site_type_distribution.to_csv(os.path.join(RUN_DIR, 'site_type_distribution.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for XGBoost...\n",
      "  train data complete\n",
      "  val data complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:02:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.873177479536645 with params: {'colsample_bytree': 0.7578115700148477, 'gamma': 0.08287634566961916, 'min_child_weight': 3, 'learning_rate': 0.12536528639802086, 'max_depth': 12, 'n_estimators': 147, 'subsample': 0.6583160158021772}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:04:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 13.772317715454664 with params: {'colsample_bytree': 0.5428623482935462, 'gamma': 0.42753182623476804, 'min_child_weight': 4, 'learning_rate': 0.195335025424085, 'max_depth': 13, 'n_estimators': 148, 'subsample': 0.868490383137451}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:06:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 13.620876725890229 with params: {'colsample_bytree': 0.9373933366506375, 'gamma': 0.334650068726291, 'min_child_weight': 7, 'learning_rate': 0.09471102815068018, 'max_depth': 17, 'n_estimators': 96, 'subsample': 0.8472767261811002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:09:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 13.681062090348542 with params: {'colsample_bytree': 0.6659707166963071, 'gamma': 0.2574097229916544, 'min_child_weight': 6, 'learning_rate': 0.17118258588458526, 'max_depth': 15, 'n_estimators': 103, 'subsample': 0.78634716525238}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:11:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 13.214840766176026 with params: {'colsample_bytree': 0.8595014774580252, 'gamma': 0.053164449712578166, 'min_child_weight': 4, 'learning_rate': 0.16358737399035927, 'max_depth': 14, 'n_estimators': 75, 'subsample': 0.8466152640066291}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:13:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 13.65329293082133 with params: {'colsample_bytree': 0.50596164616668, 'gamma': 0.3058749990163182, 'min_child_weight': 6, 'learning_rate': 0.18867793487557463, 'max_depth': 13, 'n_estimators': 145, 'subsample': 0.9626349228192372}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:15:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 15.651814947808404 with params: {'colsample_bytree': 0.5171735273002764, 'gamma': 0.33004558578977117, 'min_child_weight': 3, 'learning_rate': 0.020043046357217372, 'max_depth': 14, 'n_estimators': 57, 'subsample': 0.954149019488095}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:17:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 14.032901964572883 with params: {'colsample_bytree': 0.9366261649717827, 'gamma': 0.19355643265313816, 'min_child_weight': 5, 'learning_rate': 0.1778782013132973, 'max_depth': 17, 'n_estimators': 83, 'subsample': 0.5556243971940721}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:19:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 11.951121637402274 with params: {'colsample_bytree': 0.6271489401347604, 'gamma': 0.4961522349121672, 'min_child_weight': 2, 'learning_rate': 0.08566470358150552, 'max_depth': 9, 'n_estimators': 57, 'subsample': 0.8714300786930459}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:20:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.1268062112446 with params: {'colsample_bytree': 0.6571866577372808, 'gamma': 0.4402882371131698, 'min_child_weight': 3, 'learning_rate': 0.15426342518584454, 'max_depth': 9, 'n_estimators': 101, 'subsample': 0.5060748218042318}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:21:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.05635378322994 with params: {'colsample_bytree': 0.6821607533776404, 'gamma': 0.24691354252333325, 'min_child_weight': 2, 'learning_rate': 0.1915258815131692, 'max_depth': 8, 'n_estimators': 110, 'subsample': 0.7095200827485078}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:22:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.081574038290078 with params: {'colsample_bytree': 0.5611967864367868, 'gamma': 0.231501413267994, 'min_child_weight': 3, 'learning_rate': 0.11701695906283917, 'max_depth': 10, 'n_estimators': 55, 'subsample': 0.8614767210375238}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:23:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.660364552532704 with params: {'colsample_bytree': 0.9663087518105566, 'gamma': 0.06685774059254646, 'min_child_weight': 5, 'learning_rate': 0.027107788566750335, 'max_depth': 12, 'n_estimators': 104, 'subsample': 0.8439261859395983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:25:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.154337502082008 with params: {'colsample_bytree': 0.8125189953952469, 'gamma': 0.03862050533710559, 'min_child_weight': 2, 'learning_rate': 0.055639964011472, 'max_depth': 10, 'n_estimators': 74, 'subsample': 0.7726089732475734}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:26:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 11.754383225817286 with params: {'colsample_bytree': 0.7665240684286052, 'gamma': 0.23449997699795766, 'min_child_weight': 4, 'learning_rate': 0.11148863493502222, 'max_depth': 8, 'n_estimators': 76, 'subsample': 0.6986365847441489}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:27:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.50922013807316 with params: {'colsample_bytree': 0.7011816322561479, 'gamma': 0.3926079853515963, 'min_child_weight': 3, 'learning_rate': 0.10529490985894574, 'max_depth': 11, 'n_estimators': 143, 'subsample': 0.721472783762807}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:28:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.502539248238422 with params: {'colsample_bytree': 0.840790932505333, 'gamma': 0.0640727083447552, 'min_child_weight': 2, 'learning_rate': 0.11469778002816683, 'max_depth': 12, 'n_estimators': 110, 'subsample': 0.5248909726002511}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:30:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.142246894947673 with params: {'colsample_bytree': 0.9087844085436133, 'gamma': 0.16338809903779045, 'min_child_weight': 5, 'learning_rate': 0.12121242588273946, 'max_depth': 10, 'n_estimators': 98, 'subsample': 0.8123753247613568}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:31:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 13.60687250054473 with params: {'colsample_bytree': 0.7744824680442506, 'gamma': 0.0066344322575006, 'min_child_weight': 3, 'learning_rate': 0.01942403530860936, 'max_depth': 17, 'n_estimators': 122, 'subsample': 0.8168795835596803}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/.conda/envs/scratch/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [16:36:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"njobs\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 15.574862764036558 with params: {'colsample_bytree': 0.8433546259061147, 'gamma': 0.02807806202543872, 'min_child_weight': 5, 'learning_rate': 0.011351177781153942, 'max_depth': 9, 'n_estimators': 96, 'subsample': 0.5355049023195102}\n",
      "Best MSE: 11.754383225817286\n",
      "Best params: {'colsample_bytree': 0.7665240684286052, 'gamma': 0.23449997699795766, 'min_child_weight': 4, 'learning_rate': 0.11148863493502222, 'max_depth': 8, 'n_estimators': 76, 'subsample': 0.6986365847441489}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/m/matthew.fortier/projects/core_research/nee/util_xgb.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_final['XGBoost'] = best_predictions\n"
     ]
    }
   ],
   "source": [
    "# Check for other runs with the same distribution\n",
    "def find_identical_run():\n",
    "    for d in os.listdir(ALL_RUN_DIR):\n",
    "        if d == run:\n",
    "            continue\n",
    "        other_run_dir = os.path.join(ALL_RUN_DIR , d)\n",
    "        if not os.path.exists(os.path.join(other_run_dir, 'train_sites.txt')):\n",
    "            continue\n",
    "        with open(os.path.join(other_run_dir, 'train_sites.txt'), 'r') as f:\n",
    "            other_train_sites = f.read().split('\\n')\n",
    "        with open(os.path.join(other_run_dir, 'val_sites.txt'), 'r') as f:\n",
    "            other_val_sites = f.read().split('\\n')\n",
    "        if collections.Counter(TRAIN_SITES) == collections.Counter(other_train_sites) \\\n",
    "                and collections.Counter(VAL_SITES) == collections.Counter(other_val_sites) \\\n",
    "                and os.path.exists(os.path.join(other_run_dir, 'xgb_inference.csv')):\n",
    "            return other_run_dir\n",
    "    return None\n",
    "identical_run = find_identical_run()\n",
    "\n",
    "if os.path.exists(os.path.join(RUN_DIR, 'xgb_inference.csv')):\n",
    "    print('All files found')\n",
    "elif identical_run is not None:\n",
    "    print('Copying files')\n",
    "    items_to_copy = ['xgb.pkl', 'site_type_distribution.csv', 'xgb_inference.csv']\n",
    "    for i in items_to_copy:\n",
    "        shutil.copy(os.path.join(identical_run, i), os.path.join(RUN_DIR, i))\n",
    "else:\n",
    "    site_configuration()\n",
    "    xgb_process_data(DATA_DIR, TRAIN_SITES, VAL_SITES, RUN_DIR)\n",
    "    xgb_train_and_infer(RUN_DIR, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset / dataloader specifically for analysis\n",
    "# Includes site ID and timestamp with every sample\n",
    "\n",
    "class FluxDataset(Dataset):\n",
    "    def __init__(self, data_dir, sites, context_length=48, targets=['GPP_NT_VUT_REF']):\n",
    "        self.data_dir = data_dir\n",
    "        self.sites = sites\n",
    "        self.data = []\n",
    "        self.context_length = context_length\n",
    "        self.targets = targets\n",
    "        self.remove_columns = ['timestamp', 'NEE_VUT_REF', 'GPP_NT_VUT_REF', 'RECO_NT_VUT_REF']\n",
    "        \n",
    "        for root, _, files in os.walk(self.data_dir):\n",
    "            in_sites = False\n",
    "            for site in sites:\n",
    "                if site in root:\n",
    "                    in_sites = True\n",
    "            if not in_sites:\n",
    "                continue\n",
    "            \n",
    "\n",
    "            if 'data.csv' in files:\n",
    "                df = pd.read_csv(os.path.join(root, 'data.csv'))\n",
    "                float_cols = [c for c in df.columns if c != 'timestamp']\n",
    "                df[float_cols] = df[float_cols].astype(np.float32)\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "                with open(os.path.join(root, 'modis.pkl'), 'rb') as f:\n",
    "                    modis_data = pkl.load(f)\n",
    "                with open(os.path.join(root, 'meta.json'), 'r') as f:\n",
    "                    meta = json.load(f)\n",
    "\n",
    "                self.data.append((meta, df, modis_data))\n",
    "        \n",
    "        self.lookup_table = []\n",
    "        for i, d in enumerate(self.data):\n",
    "            _, df, _ = d\n",
    "            for r in range(self.context_length, len(df)+1):\n",
    "                self.lookup_table.append((i,r))\n",
    "        \n",
    "        col_df = self.data[0][1].drop(columns=self.remove_columns)\n",
    "        self.tabular_columns = list(col_df.columns)\n",
    "        self.modis_bands = max([v.shape[0] for v in list(self.data[0][2].values())])\n",
    "\n",
    "    def num_channels(self):\n",
    "        _, _, modis = self.data[0]\n",
    "        return modis[list(modis.keys())[0]].shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lookup_table)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        site_num, row_max = self.lookup_table[idx]\n",
    "        row_min = row_max - (self.context_length)\n",
    "\n",
    "        meta, df, modis = self.data[site_num]\n",
    "        rows = df.iloc[row_min:row_max]\n",
    "\n",
    "        rows = rows.reset_index(drop=True)\n",
    "        modis_data = []\n",
    "        timestamps = list(rows['timestamp'])\n",
    "        for i, ts in enumerate(timestamps):\n",
    "            pixels = modis.get(ts, None)\n",
    "            if pixels is not None:\n",
    "                modis_data.append((i, torch.tensor(pixels[:,1:9,1:9], dtype=torch.float32)))\n",
    "        \n",
    "        targets = torch.tensor(rows[self.targets].values)\n",
    "        row_values = torch.tensor(rows.drop(columns=self.remove_columns).values)\n",
    "        mask = row_values.isnan()\n",
    "        row_values = row_values.nan_to_num(-1.0) # just needs a numeric value, doesn't matter what\n",
    "\n",
    "        ### Analysis variables\n",
    "        timestamp = timestamps[-1]\n",
    "        site_id = meta['SITE_ID']\n",
    "        return row_values, mask, modis_data, targets, timestamp, site_id\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    row_values, mask, modis_data, targets, timestamps, site_ids = zip(*batch)\n",
    "\n",
    "    # Normal attributes\n",
    "    row_values = torch.stack(row_values, dim=0)\n",
    "    mask = torch.stack(mask, dim=0)\n",
    "    targets = torch.stack(targets, dim=0)\n",
    "\n",
    "    # List of modis data. Tuples of (batch, timestep, data)\n",
    "    modis_list = []\n",
    "    for b, batch in enumerate(modis_data):\n",
    "        for t, data in batch:\n",
    "            modis_list.append((b, t, data))\n",
    "\n",
    "    return row_values, mask, modis_list, targets, list(timestamps), list(site_ids)\n",
    "\n",
    "def FluxDataLoader(data_dir, sites, context_length = 32, targets=['NEE_VUT_REF'], **kwargs):\n",
    "    ds = FluxDataset(data_dir, sites, context_length=context_length, targets=targets)\n",
    "    return DataLoader(ds, collate_fn=custom_collate_fn, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = FluxDataLoader(DATA_DIR, VAL_SITES, num_workers=16, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22866 [00:00<?, ?it/s]/home/matt/miniconda3/envs/scratch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 22866/22866 [1:20:01<00:00,  4.76it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(RUN_DIR, 'config.yml'), 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "inference_df = pd.read_csv(os.path.join(RUN_DIR, 'xgb_inference.csv'))\n",
    "inference_df['timestamp'] = pd.to_datetime(inference_df['timestamp'])\n",
    "inference_df.set_index(['SITE_ID', 'timestamp'], drop=True, inplace=True)\n",
    "inference_df['Deep Model'] = np.nan\n",
    "inference_df.drop(columns=['XGBoost'], inplace=True)\n",
    "config['model']['spectral_data_channels'] = dl.dataset.num_channels()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = Perceiver(PerceiverConfig(**config['model'])) \n",
    "checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "for row_values, mask, modis_data, targets, timestamp, site_id in tqdm(dl):\n",
    "    with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "        op = model(row_values, mask, modis_data, targets)\n",
    "        outputs = op['logits'][:,-1].cpu().tolist()\n",
    "\n",
    "        # Update inference df\n",
    "        idx = pd.MultiIndex.from_tuples(zip(site_id, timestamp), names=['SITE_ID', 'timestamp'])\n",
    "        inference_df.update(pd.DataFrame(outputs, columns=['Deep Model'], index=idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df.to_csv(os.path.join(RUN_DIR, 'deep_inference.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
