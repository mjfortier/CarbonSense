{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process ICOS-WW data\n",
    "- replace sentinel values with NaN\n",
    "- downsample from half-hourly to hourly (if needed for each site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_VA = ['TA_F', 'SW_IN_F', 'LW_IN_F', 'VPD_F', 'PA_F', 'P_F', 'WS_F', 'WD', 'RH', 'USTAR', 'NETRAD', 'PPFD_IN', 'PPFD_DIF', 'PPFD_OUT', 'SW_DIF', 'SW_OUT', 'LW_OUT',\n",
    "        'CO2_F_MDS', 'G_F_MDS', 'LE_F_MDS', 'H_F_MDS', 'NEE_VUT_REF', 'RECO_NT_VUT_REF', 'RECO_DT_VUT_REF', 'GPP_NT_VUT_REF', 'GPP_DT_VUT_REF']\n",
    "COLS_QC = [f'{c}_QC' for c in COLS_VA]\n",
    "COLS_TS = ['TIMESTAMP_START']\n",
    "\n",
    "collection = 'icos-ww'\n",
    "\n",
    "INPUT_DIR = os.path.join('data', 'raw', collection, 'unzipped')\n",
    "META_FILE = os.path.join('data', 'raw', collection, 'site_data.csv')\n",
    "OUTPUT_DIR = os.path.join('data', 'intermediate', 'test_int_1', collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_site_dataframe(df, downsample=True):\n",
    "    df = df.replace(-9999.0, np.nan)\n",
    "    for column in COLS_VA + COLS_QC:\n",
    "        if column not in df.columns:\n",
    "            df[column] = np.nan\n",
    "    \n",
    "    df_ts = df[COLS_TS]\n",
    "    df_va = df[COLS_VA]\n",
    "    df_qc = df[COLS_QC]\n",
    "\n",
    "    if downsample:\n",
    "        # Average to hourly data\n",
    "        grouping_key = np.arange(len(df_va)) // 2\n",
    "        df_va = df_va.groupby(grouping_key).mean().reset_index(drop=True)\n",
    "        df_ts = df_ts.iloc[::2,:].reset_index(drop=True)\n",
    "        df_qc = df_qc.iloc[::2,:].reset_index(drop=True)\n",
    "    \n",
    "    # Double precipitation, as this should not be averaged\n",
    "    df_va['P_F'] = df_va['P_F'] * 2.0\n",
    "    df = pd.concat([df_ts, df_va, df_qc], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for site in os.listdir(INPUT_DIR):\n",
    "    files = os.listdir(os.path.join(INPUT_DIR, site))\n",
    "    fluxnet_compatible_files = [f for f in files if 'FLUXNET2015_FULLSET_HH' in f and 'VARINFO' not in f]\n",
    "    if len(fluxnet_compatible_files) != 1:\n",
    "        print(f'ERROR: No compatible file found for {site}')\n",
    "        continue\n",
    "    file = fluxnet_compatible_files[0]\n",
    "    data.append((site, os.path.join(INPUT_DIR, site, file), collection, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/raw/icos-ww/unzipped/IT-Tor/FLX_IT-Tor_FLUXNET2015_FULLSET_HH_2008-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CH-Lae/FLX_CH-Lae_FLUXNET2015_FULLSET_HH_2004-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FR-LGt/FLX_FR-LGt_FLUXNET2015_FULLSET_HH_2017-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CH-Dav/FLX_CH-Dav_FLUXNET2015_FULLSET_HH_1997-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FI-Hyy/FLX_FI-Hyy_FLUXNET2015_FULLSET_HH_1996-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/IT-Ren/FLX_IT-Ren_FLUXNET2015_FULLSET_HH_1999-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FR-Lam/FLX_FR-Lam_FLUXNET2015_FULLSET_HH_2005-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/SE-Htm/FLX_SE-Htm_FLUXNET2015_FULLSET_HH_2015-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/SE-Svb/FLX_SE-Svb_FLUXNET2015_FULLSET_HH_2014-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/BE-Dor/FLX_BE-Dor_FLUXNET2015_FULLSET_HH_2011-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/SE-Ros/FLX_SE-Ros_FLUXNET2015_FULLSET_HH_2014-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-Hai/FLX_DE-Hai_FLUXNET2015_FULLSET_HH_2000-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FR-Bil/FLX_FR-Bil_FLUXNET2015_FULLSET_HH_2014-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/BE-Maa/FLX_BE-Maa_FLUXNET2015_FULLSET_HH_2016-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CZ-Stn/FLX_CZ-Stn_FLUXNET2015_FULLSET_HH_2010-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CZ-RAJ/FLX_CZ-RAJ_FLUXNET2015_FULLSET_HH_2012-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/IT-MBo/FLX_IT-MBo_FLUXNET2015_FULLSET_HH_2003-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FR-Fon/FLX_FR-Fon_FLUXNET2015_FULLSET_HH_2005-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FR-Hes/FLX_FR-Hes_FLUXNET2015_FULLSET_HH_2014-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/IT-BCi/FLX_IT-BCi_FLUXNET2015_FULLSET_HH_2004-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/SE-Deg/FLX_SE-Deg_FLUXNET2015_FULLSET_HH_2001-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-Kli/FLX_DE-Kli_FLUXNET2015_FULLSET_HH_2004-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CH-Fru/FLX_CH-Fru_FLUXNET2015_FULLSET_HH_2005-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-Tha/FLX_DE-Tha_FLUXNET2015_FULLSET_HH_1996-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/GL-Dsk/FLX_GL-Dsk_FLUXNET2015_FULLSET_HH_2020-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FI-Sii/FLX_FI-Sii_FLUXNET2015_FULLSET_HH_2016-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/IT-Lav/FLX_IT-Lav_FLUXNET2015_FULLSET_HH_2003-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DK-Sor/FLX_DK-Sor_FLUXNET2015_FULLSET_HH_1996-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CZ-KrP/FLX_CZ-KrP_FLUXNET2015_FULLSET_HH_2014-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FR-Tou/FLX_FR-Tou_FLUXNET2015_FULLSET_HH_2018-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-RuW/FLX_DE-RuW_FLUXNET2015_FULLSET_HH_2012-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/IT-Lsn/FLX_IT-Lsn_FLUXNET2015_FULLSET_HH_2016-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/RU-Fy2/FLX_RU-Fy2_FLUXNET2015_FULLSET_HH_2015-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-Gri/FLX_DE-Gri_FLUXNET2015_FULLSET_HH_2004-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/ES-LJu/FLX_ES-LJu_FLUXNET2015_FULLSET_HH_2004-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/IE-Cra/FLX_IE-Cra_FLUXNET2015_FULLSET_HH_2020-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CZ-wet/FLX_CZ-wet_FLUXNET2015_FULLSET_HH_2006-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/ES-Abr/FLX_ES-Abr_FLUXNET2015_FULLSET_HH_2015-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CH-Oe2/FLX_CH-Oe2_FLUXNET2015_FULLSET_HH_2004-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-RuS/FLX_DE-RuS_FLUXNET2015_FULLSET_HH_2011-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-RuR/FLX_DE-RuR_FLUXNET2015_FULLSET_HH_2011-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CZ-BK1/FLX_CZ-BK1_FLUXNET2015_FULLSET_HH_2004-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/ES-LM2/FLX_ES-LM2_FLUXNET2015_FULLSET_HH_2014-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-Akm/FLX_DE-Akm_FLUXNET2015_FULLSET_HH_2009-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/BE-Lon/FLX_BE-Lon_FLUXNET2015_FULLSET_HH_2004-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/SE-Nor/FLX_SE-Nor_FLUXNET2015_FULLSET_HH_2014-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FI-Qvd/FLX_FI-Qvd_FLUXNET2015_FULLSET_HH_2018-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/IT-Cp2/FLX_IT-Cp2_FLUXNET2015_FULLSET_HH_2012-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FR-Gri/FLX_FR-Gri_FLUXNET2015_FULLSET_HH_2004-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-Hzd/FLX_DE-Hzd_FLUXNET2015_FULLSET_HH_2010-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DK-Gds/FLX_DK-Gds_FLUXNET2015_FULLSET_HH_2020-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/ES-LM1/FLX_ES-LM1_FLUXNET2015_FULLSET_HH_2014-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/IT-BFt/FLX_IT-BFt_FLUXNET2015_FULLSET_HH_2019-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/BE-Bra/FLX_BE-Bra_FLUXNET2015_FULLSET_HH_1996-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CH-Cha/FLX_CH-Cha_FLUXNET2015_FULLSET_HH_2005-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CZ-Lnz/FLX_CZ-Lnz_FLUXNET2015_FULLSET_HH_2015-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-Obe/FLX_DE-Obe_FLUXNET2015_FULLSET_HH_2008-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/IL-Yat/FLX_IL-Yat_FLUXNET2015_FULLSET_HH_2000-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FI-Ken/FLX_FI-Ken_FLUXNET2015_FULLSET_HH_2018-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/BE-Lcr/FLX_BE-Lcr_FLUXNET2015_FULLSET_HH_2019-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/CH-Aws/FLX_CH-Aws_FLUXNET2015_FULLSET_HH_2006-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FR-FBn/FLX_FR-FBn_FLUXNET2015_FULLSET_HH_2008-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FI-Var/FLX_FI-Var_FLUXNET2015_FULLSET_HH_2016-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/IT-SR2/FLX_IT-SR2_FLUXNET2015_FULLSET_HH_2013-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/GF-Guy/FLX_GF-Guy_FLUXNET2015_FULLSET_HH_2004-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/RU-Fyo/FLX_RU-Fyo_FLUXNET2015_FULLSET_HH_1998-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/ES-Agu/FLX_ES-Agu_FLUXNET2015_FULLSET_HH_2006-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-HoH/FLX_DE-HoH_FLUXNET2015_FULLSET_HH_2015-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/BE-Vie/FLX_BE-Vie_FLUXNET2015_FULLSET_HH_1996-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/FR-Aur/FLX_FR-Aur_FLUXNET2015_FULLSET_HH_2005-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/DE-Geb/FLX_DE-Geb_FLUXNET2015_FULLSET_HH_2001-2020_beta-3.csv...\n",
      "Processing data/raw/icos-ww/unzipped/ES-Cnd/FLX_ES-Cnd_FLUXNET2015_FULLSET_HH_2014-2020_beta-3.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n",
      "/tmp/ipykernel_3073/1648976969.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/raw/icos-ww/unzipped/FI-Let/FLX_FI-Let_FLUXNET2015_FULLSET_HH_2009-2020_beta-3.csv...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "for site, file, source, downsample in data:\n",
    "    print(f'Processing {file}...')\n",
    "    site_dir = os.path.join(OUTPUT_DIR, site)\n",
    "    if not os.path.exists(site_dir):\n",
    "        os.makedirs(site_dir)\n",
    "    \n",
    "    site_df = pd.read_csv(file)\n",
    "    processed_df = process_site_dataframe(site_df, downsample=downsample)\n",
    "    min_time = processed_df['TIMESTAMP_START'].min()\n",
    "    max_time = processed_df['TIMESTAMP_START'].max()\n",
    "    outfile = os.path.join(site_dir, f'{min_time}_{max_time}_{source}.csv')\n",
    "    processed_df.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/intermediate/test_int_1/icos-ww/site_data.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile(META_FILE, os.path.join(OUTPUT_DIR, 'site_data.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
