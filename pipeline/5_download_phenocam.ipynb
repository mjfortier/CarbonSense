{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenocam Data Retrieval\n",
    "# This script can take many hours to complete, but it is designed to be able to stop suddenly and pick back up where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from time import sleep\n",
    "import pickle as pkl\n",
    "\n",
    "from shapely.geometry import Polygon, Point\n",
    "from pyproj import CRS, Transformer\n",
    "from pyproj.aoi import AreaOfInterest\n",
    "from pyproj.database import query_utm_crs_info\n",
    "from pathlib import Path\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('data')\n",
    "MERGED_DIR = DATA_DIR / 'merged'\n",
    "SITES = os.listdir(MERGED_DIR)\n",
    "CONFIG_FILE = Path('config.json')\n",
    "\n",
    "with open(CONFIG_FILE, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "BASE_URL = 'https://phenocam.nau.edu'\n",
    "MAX_DIST = config['phenocam']['max_distance_from_tower_m']\n",
    "camera_url = lambda camera: f'{BASE_URL}/api/middayimages/{camera}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon_wkt(lat, lon, offset_m) -> Polygon:\n",
    "    \"\"\"Generate a WKT polygon based on the provided lat, lon, and offset in meters.\n",
    "    \n",
    "    Args:\n",
    "        lat (float): Latitude of the site in WGS84.\n",
    "        lon (float): Longitude of the site in WGS84.\n",
    "        offset_m (int): Number of meters to offset in each direction from the site.\n",
    "        \n",
    "    Returns:\n",
    "        Polygon: A Shapely polygon representing the box around the site.\n",
    "    \"\"\"\n",
    "    utm_crs_info = query_utm_crs_info(\n",
    "        area_of_interest=AreaOfInterest(west_lon_degree=lon, south_lat_degree=lat, east_lon_degree=lon, north_lat_degree=lat),\n",
    "        datum_name=\"WGS 84\"\n",
    "    )[0]\n",
    "    utm_crs = CRS.from_epsg(utm_crs_info.code)\n",
    "    transformer_utm_to_wgs84 = Transformer.from_crs(utm_crs, \"EPSG:4326\", always_xy=True)\n",
    "    transformer_wgs84_to_utm = Transformer.from_crs(\"EPSG:4326\", utm_crs, always_xy=True)\n",
    "\n",
    "    # Calculate box bounds\n",
    "    x, y = transformer_wgs84_to_utm.transform(lon, lat)\n",
    "    bottom_left = (x - offset_m, y - offset_m)\n",
    "    bottom_right = (x + offset_m, y - offset_m)\n",
    "    top_right = (x + offset_m, y + offset_m)\n",
    "    top_left = (x - offset_m, y + offset_m)\n",
    "\n",
    "    # Create the polygon in WGS84\n",
    "    box = Polygon([bottom_left, bottom_right, top_right, top_left, bottom_left])\n",
    "    lon_lat_coords = [transformer_utm_to_wgs84.transform(xx, yy) for xx, yy in zip(*box.exterior.xy)]\n",
    "    geo_polygon = Polygon(lon_lat_coords)\n",
    "\n",
    "    return geo_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timestamp(ts):\n",
    "  # ts - int representation YYYYMMDDHHMM, ex: 202108120630\n",
    "  sts = str(ts)\n",
    "  return f'{sts[0:4]}-{sts[4:6]}-{sts[6:8]}'\n",
    "\n",
    "\n",
    "def unformat_timestamp(ts):\n",
    "  # ts - string representation 'YYYY_MM_DD'\n",
    "  # assume output is solar noon\n",
    "  return int(f\"{''.join(ts.split('-'))}1200\")\n",
    "\n",
    "\n",
    "def get_all_timestamps(min_date, max_date):\n",
    "    min_date_formatted = pd.to_datetime(min_date, format='%Y%m%d%H%M')\n",
    "    max_date_formatted = pd.to_datetime(max_date, format='%Y%m%d%H%M')\n",
    "    timestamp_range = pd.date_range(start=min_date_formatted, end=max_date_formatted, freq='30T')\n",
    "    timestamp_range_int = timestamp_range.strftime('%Y%m%d%H%M').astype(int)\n",
    "    return list(timestamp_range_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(camera):\n",
    "    try:\n",
    "        response = requests.get(camera_url(camera))\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}, {response.text}\")\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_images(image_paths, downloaded_images):\n",
    "    for i in image_paths:\n",
    "        img_file = DATA_DIR/'phenocam'/i.split('/')[-1]\n",
    "        url = BASE_URL+i\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(img_file, \"wb\") as file:\n",
    "                    file.write(response.content)\n",
    "                downloaded_images[img_file] = True\n",
    "            # else:\n",
    "            #     print(f\"\\tError: {response.status_code}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"\\tAn error occurred: {e}\")\n",
    "    \n",
    "        delay = np.random.uniform(low=0.05, high=0.1) # average 75ms wait time\n",
    "        sleep(delay)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [38:12:25<00:00, 329.84s/it]     \n"
     ]
    }
   ],
   "source": [
    "phenocam_sites = pd.read_csv('phenocam_sites.csv')\n",
    "downloaded_images = {i: True for i in os.listdir(DATA_DIR/'phenocam')}\n",
    "\n",
    "# After every camera analysis, this function caches progress\n",
    "for site in tqdm(SITES):\n",
    "    # print(site)\n",
    "    with open(MERGED_DIR/site/'meta.json', 'r') as f:\n",
    "        site_meta = json.loads(f.read())\n",
    "    min_date = site_meta['MIN_DATE']\n",
    "    max_date = site_meta['MAX_DATE']\n",
    "    \n",
    "    cameras = []\n",
    "    allowable_poly = get_polygon_wkt(site_meta['LOCATION_LAT'], site_meta['LOCATION_LON'], MAX_DIST)\n",
    "    for i, row in phenocam_sites.iterrows():\n",
    "        p = Point(row['LOCATION_LON'], row['LOCATION_LAT'])\n",
    "        if allowable_poly.contains(p):\n",
    "            cameras.append(row['Camera'])\n",
    "    \n",
    "    if os.path.exists(MERGED_DIR/site/'phenocam.pkl'):\n",
    "        with open(MERGED_DIR/site/'phenocam.pkl', 'rb') as f:\n",
    "            phenocam_lookup = pkl.load(f)\n",
    "    else:\n",
    "        phenocam_lookup = {d: [] for d in get_all_timestamps(min_date, max_date)}\n",
    "\n",
    "    # if len(cameras) > 1:\n",
    "    #     print(f'\\tmore than one camera for {site}')\n",
    "    # Currently we are not using IR images.\n",
    "    for camera in cameras:\n",
    "        image_list = get_image_list(camera)\n",
    "        filtered_download_list = []\n",
    "        for i in image_list:\n",
    "            ts = unformat_timestamp(i['imgdate'])\n",
    "            if ts < min_date or max_date < ts:\n",
    "                continue\n",
    "            \n",
    "            img_file = i['imgpath'].split('/')[-1]\n",
    "            if img_file not in phenocam_lookup[ts]:\n",
    "                phenocam_lookup[ts].append(img_file)\n",
    "            \n",
    "            if not downloaded_images.get(img_file, False):\n",
    "                filtered_download_list.append(i['imgpath'])\n",
    "        # if len(filtered_download_list) > 0:\n",
    "        #     print(f'\\tDownlaoding {len(filtered_download_list)} files')\n",
    "        download_images(filtered_download_list, downloaded_images)\n",
    "        with open(MERGED_DIR/site/'phenocam.pkl', 'wb') as f:\n",
    "             pkl.dump(phenocam_lookup, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
