{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Tuple, Union, Any\n",
    "import pickle as pkl\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC_PREDICTORS = ('DOY', 'TOD', 'TA', 'P', 'RH', 'VPD', 'PA', 'CO2', 'SW_IN', 'SW_OUT', 'LW_IN', 'LW_OUT', 'NETRAD', 'PPFD_IN', 'PPFD_OUT',\n",
    "                 'TS_1', 'TS_2', 'TS_3', 'TS_4', 'TS_5', 'G', 'H', 'LE', 'WS', 'WD', 'USTAR')\n",
    "\n",
    "EC_TARGETS = ('NEE', 'GPP_DT', 'GPP_NT', 'RECO_DT', 'RECO_NT', 'FCH4')\n",
    "\n",
    "DEFAULT_NORM = {\n",
    "    'DOY': {'cyclic': True, 'norm_max': 366.0, 'norm_min': 0.0},\n",
    "    'TOD': {'cyclic': True, 'norm_max': 24.0, 'norm_min': 0.0},\n",
    "    'TA': {'cyclic': False, 'norm_max': 80.0, 'norm_min': -80.0},\n",
    "    'P': {'cyclic': False, 'norm_max': 50.0, 'norm_min': 0.0},\n",
    "    'RH': {'cyclic': False, 'norm_max': 100.0, 'norm_min': 0.0},\n",
    "    'VPD': {'cyclic': False, 'norm_max': 110.0, 'norm_min': 0.0},\n",
    "    'PA': {'cyclic': False, 'norm_max': 110.0, 'norm_min': 0.0},\n",
    "    'CO2': {'cyclic': False, 'norm_max': 750.0, 'norm_min': 0.0},\n",
    "    'SW_IN': {'cyclic': False, 'norm_max': 1500.0, 'norm_min': -1500.0},\n",
    "    'SW_OUT': {'cyclic': False, 'norm_max': 500.0, 'norm_min': -500.0},\n",
    "    'LW_IN': {'cyclic': False, 'norm_max': 1000.0, 'norm_min': -1000.0},\n",
    "    'LW_OUT': {'cyclic': False, 'norm_max': 1000.0, 'norm_min': -1000.0},\n",
    "    'NETRAD': {'cyclic': False, 'norm_max': 1000.0, 'norm_min': -1000.0},\n",
    "    'PPFD_IN': {'cyclic': False, 'norm_max': 2500.0, 'norm_min': -2500.0},\n",
    "    'PPFD_OUT': {'cyclic': False, 'norm_max': 1000.0, 'norm_min': -1000.0},\n",
    "    'TS_1': {'cyclic': False, 'norm_max': 40.0, 'norm_min': -40.0},\n",
    "    'TS_2': {'cyclic': False, 'norm_max': 40.0, 'norm_min': -40.0},\n",
    "    'TS_3': {'cyclic': False, 'norm_max': 40.0, 'norm_min': -40.0},\n",
    "    'TS_4': {'cyclic': False, 'norm_max': 40.0, 'norm_min': -40.0},\n",
    "    'TS_5': {'cyclic': False, 'norm_max': 40.0, 'norm_min': -40.0},\n",
    "    'USTAR': {'cyclic': False, 'norm_max': 4.0, 'norm_min': -4.0},\n",
    "    'G': {'cyclic': False, 'norm_max': 700.0, 'norm_min': -700.0},\n",
    "    'H': {'cyclic': False, 'norm_max': 700.0, 'norm_min': -700.0},\n",
    "    'LE': {'cyclic': False, 'norm_max': 700.0, 'norm_min': -700.0},\n",
    "    'WD': {'cyclic': True, 'norm_max': 360.0, 'norm_min': 0.0},\n",
    "    'WS': {'cyclic': False, 'norm_max': 100.0, 'norm_min': -100.0},\n",
    "\n",
    "    'NEE': {'cyclic': False, 'norm_max': 50.0, 'norm_min': -50.0},\n",
    "    'GPP_DT': {'cyclic': False, 'norm_max': 40.0, 'norm_min': -40.0},\n",
    "    'GPP_NT': {'cyclic': False, 'norm_max': 40.0, 'norm_min': -40.0},\n",
    "    'RECO_DT': {'cyclic': False, 'norm_max': 30.0, 'norm_min': -30.0},\n",
    "    'RECO_NT': {'cyclic': False, 'norm_max': 30.0, 'norm_min': -30.0},\n",
    "    'FCH4': {'cyclic': False, 'norm_max': 800.0, 'norm_min': -800.0}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing site data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:00<00:00, 91275.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing sites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:28<00:00,  4.73it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@dataclass\n",
    "class CarbonSenseConfig:\n",
    "    '''Configuration for CarbonSenseV2 dataloader and preprocessor\n",
    "\n",
    "    targets - variable selection for targets. Must be a subset of EC_TARGETS\n",
    "    targets_max_qc - maximum QC flag (inclusive) to allow for target values. A lower value will result\n",
    "                     in fewer usable samples, but they will be of higher quality\n",
    "    predictors - variable selection for predictors. Must be a subset of EC_PREDICTORS\n",
    "    predictors_max_qc - similar to targets_max_qc, but applied to predictor variables\n",
    "    normalization_config - dictionary object used for normalizing variables. Custom dictionaries can\n",
    "                           be supplied, but should be based on the DEFAULT_NORM template\n",
    "\n",
    "    suffix - file suffix for preprocessed tabular data files. This is used by the proprocessing script to\n",
    "             normalize and filter variables based on max QC values. If the data loader is passed a config with\n",
    "             a suffix string and does not locate the appropriate files, it will run the proprocessor automatically.\n",
    "             For example, if suffix = '_proc', then the preprocessor will make a 'data_proc.csv' for each site.\n",
    "             **NOTE** if a suffix file is already present, it will effectively ignore all max QC, normalization,\n",
    "             and variable selection parameters, as it will assume these operations are already complete. This can\n",
    "             be circumvented by passing force_overwrite = True.\n",
    "    force_overwrite - whether or not to rerun the preprocessing even if the suffix file is found.\n",
    "\n",
    "    context_window_length - how many timesteps should be included with each example. This is the 'context window'.\n",
    "                            For example, if context_window_length = 4, then every sample will contain 4\n",
    "                            consecutive timesteps worth of data, for both predictors and targets.\n",
    "    image_timestep_threshold - allows the dataloader to look back past the beginning of the context window for any\n",
    "                               MODIS / phenocam imagery. For example, if image_timestep_threshold = 48, then the\n",
    "                               data loader will look back up to 48 timesteps (24 hours) for images if none are found\n",
    "                               in the context window. This is useful for models which only have a context window of 1,\n",
    "                               but still want to have imagery with most samples.\n",
    "                               **NOTE** the batch provided by the dataloader may lie about when the images were taken.\n",
    "    '''\n",
    "\n",
    "    # Preprocessor arguments\n",
    "    targets: Tuple[str] = EC_TARGETS\n",
    "    targets_max_qc: int = 1\n",
    "    predictors: Tuple[str] = EC_PREDICTORS\n",
    "    predictors_max_qc: int = 1\n",
    "\n",
    "    normalize_predictors: bool = True\n",
    "    normalize_targets: bool = False\n",
    "    normalization_config: Dict = field(default_factory = lambda: (DEFAULT_NORM))\n",
    "    suffix: str = '_proc'\n",
    "    force_overwrite: bool = False\n",
    "\n",
    "    # Dataloader arguments\n",
    "    context_window_length: int = 16\n",
    "    image_timestep_threshold: int = 0\n",
    "    use_modis: bool = True\n",
    "    use_phenocam: bool = True\n",
    "    phenocam_resolution: Tuple = (512, 512)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(\n",
    "        data_dir: Union[str, os.PathLike],\n",
    "        config: CarbonSenseConfig):\n",
    "    if config.suffix == '':\n",
    "        print('ERROR: Cannot overwrite original data')\n",
    "        return\n",
    "    data_path = Path(data_dir)\n",
    "    sites = os.listdir(data_path / 'site_data')\n",
    "\n",
    "    print('Preprocessing site data...')\n",
    "    for site in tqdm(sites):\n",
    "        site_path = data_path / 'site_data' / site\n",
    "        outfile = site_path / f'data{config.suffix}.csv'\n",
    "        if os.path.exists(outfile) and not config.force_overwrite:\n",
    "            continue\n",
    "        df = pd.read_csv(site_path / 'data.csv')\n",
    "\n",
    "        # Delete values with a QC flag higher than the maximum specified in the config\n",
    "        for pred in config.predictors:\n",
    "            if pred == 'DOY' or pred == 'TOD':\n",
    "                continue\n",
    "            df.loc[df[f'{pred}_QC'] > config.predictors_max_qc, pred] = np.nan\n",
    "        for targ in config.targets:\n",
    "            df.loc[df[f'{targ}_QC'] > config.targets_max_qc, targ] = np.nan\n",
    "\n",
    "        # Filter variables (and get rid of QC columns)\n",
    "        df = df[['timestamp'] + list(config.predictors) + list(config.targets)]\n",
    "\n",
    "        # Min-max normalization\n",
    "        if config.normalize_predictors:\n",
    "            for pred in config.predictors:\n",
    "                vmax = config.normalization_config[pred]['norm_max']\n",
    "                vmin = config.normalization_config[pred]['norm_min']\n",
    "                vmid = (vmax + vmin) / 2\n",
    "                vrange = vmax - vmin\n",
    "                cyclic = config.normalization_config[pred]['cyclic']\n",
    "                if cyclic:\n",
    "                    vrange /= 2\n",
    "\n",
    "                df.loc[~df[pred].between(vmin, vmax), pred] = np.nan\n",
    "                df[pred] = (df[pred] - vmid) / vrange\n",
    "\n",
    "        if config.normalize_targets:\n",
    "            for targ in config.targets:\n",
    "                vmax = config.normalization_config[targ]['norm_max']\n",
    "                vmin = config.normalization_config[targ]['norm_min']\n",
    "                vmid = (vmax + vmin) / 2\n",
    "                vrange = vmax - vmin\n",
    "                cyclic = config.normalization_config[targ]['cyclic']\n",
    "                if cyclic:\n",
    "                    vrange /= 2\n",
    "\n",
    "                df.loc[~df[targ].between(vmin, vmax), targ] = np.nan\n",
    "                df[targ] = (df[targ] - vmid) / vrange\n",
    "            \n",
    "        df.to_csv(outfile, index=False)\n",
    "    return\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CarbonSenseBatch:\n",
    "    sites: Tuple[str] # one value for each sample\n",
    "    columns: Tuple[str] # common mapping for all samples in the batch\n",
    "    timestamps: Union[Tuple, np.ndarray]\n",
    "    ec_values: np.ndarray # all eddy covariance data: (batch, context_window, values)\n",
    "    modis: Tuple # all modis data: (batch, (timestamp, ndarray))\n",
    "    phenocam: Tuple # all phenocam data: (batch, (timestamp, ndarray))\n",
    "\n",
    "    def to(self, device: Any):\n",
    "        '''\n",
    "        .to(device) is provided with this dataclass as a shortcut to individually moving\n",
    "        every piece of data in the class.\n",
    "        '''\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class CarbonSenseDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_dir: Union[str, os.PathLike],\n",
    "                 config: CarbonSenseConfig):\n",
    "        self.data_path = Path(data_dir)\n",
    "        self.config = config\n",
    "\n",
    "        preprocess_data(data_dir, self.config)\n",
    "\n",
    "        self.window_len = self.config.context_window_length\n",
    "        self.datafile = f'data{self.config.suffix}.csv'\n",
    "        self.sites = sorted(os.listdir(self.data_path / 'site_data'))\n",
    "\n",
    "        self.data = []\n",
    "        print('Indexing sites...')\n",
    "        for site in tqdm(self.sites):\n",
    "            df = pd.read_csv(self.data_path / 'site_data' / site / self.datafile, skiprows=range(1,self.window_len))\n",
    "            idx = df[df[list(self.config.targets)].notnull().any(axis=1)].index.to_list()\n",
    "            self.data.extend([(site, i) for i in idx])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _load_image(self, filename):\n",
    "        with Image.open(self.data_path / 'phenocam' / filename) as img:\n",
    "            return img.convert(\"RGB\")\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Find the relevant file\n",
    "        site, index = self.data[idx]\n",
    "        ec_file = self.data_path / 'site_data' / site / self.datafile\n",
    "        df = pd.read_csv(ec_file, skiprows=range(1,1+index), nrows=self.window_len)\n",
    "\n",
    "        # Get timestamps\n",
    "        ec_timestamps = df['timestamp'].to_list()\n",
    "        if self.config.image_timestep_threshold > 0:\n",
    "            img_idx_range = range(1,max(2,1+index-self.config.image_timestep_threshold))\n",
    "            df_ts = pd.read_csv(ec_file, skiprows=img_idx_range, nrows=self.window_len+self.config.image_timestep_threshold)\n",
    "            ec_timestamps = df_ts['timestamp'].to_list()\n",
    "        \n",
    "        # EC data\n",
    "        ec_data = df.drop(columns='timestamp').values\n",
    "        ec_cols = tuple(df.drop(columns='timestamp').columns)\n",
    "\n",
    "        # MODIS data\n",
    "        modis_data = []\n",
    "        modis_file = self.data_path / 'site_data' / site / 'modis.pkl'\n",
    "        if self.config.use_modis and os.path.exists(modis_file):\n",
    "            with open(modis_file, 'rb') as f:\n",
    "                all_modis_data = pkl.load(f)\n",
    "            modis_data = [(ts, im) for ts, im in all_modis_data.items() if ts in ec_timestamps]\n",
    "\n",
    "        # Phenocam data\n",
    "        phenocam_data = []\n",
    "        phenocam_file = self.data_path / 'site_data' / site / 'phenocam.pkl'\n",
    "        if self.config.use_phenocam and os.path.exists(phenocam_file):\n",
    "            with open(phenocam_file, 'rb') as f:\n",
    "                phenocam_map = pkl.load(f)\n",
    "            filtered_phenocam_map = [(ts, f) for ts, f in phenocam_map.items() if ts in ec_timestamps]\n",
    "            for timestamp, files in filtered_phenocam_map:\n",
    "                images = []\n",
    "                for file in files:\n",
    "                    resized_img = self._load_image(file)\n",
    "                    images.append(np.array(resized_img, dtype=np.float32)/255.0)\n",
    "                    # TODO: Resize images?\n",
    "                phenocam_data.append((timestamp, images))\n",
    "\n",
    "\n",
    "        return site, ec_cols, ec_timestamps, ec_data, modis_data, phenocam_data\n",
    "\n",
    "\n",
    "config = CarbonSenseConfig(targets=['NEE'])\n",
    "ds = CarbonSenseDataset('data/carbonsense_v2', config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=1296x960 at 0x7FF6AEBB2790>\n",
      "<PIL.Image.Image image mode=RGB size=2592x1944 at 0x7FF6AEBB2520>\n"
     ]
    }
   ],
   "source": [
    "site, ec_cols, ec_timestamps, ec_data, modis_data, phenocam_data = ds.__getitem__(40343385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(201903061200,\n",
       "  [array([[[0.21176471, 0.26666668, 0.4117647 ],\n",
       "           [0.21176471, 0.26666668, 0.4117647 ],\n",
       "           [0.21176471, 0.26666668, 0.4117647 ],\n",
       "           ...,\n",
       "           [0.41568628, 0.54901963, 0.59607846],\n",
       "           [0.4117647 , 0.54509807, 0.5921569 ],\n",
       "           [0.40784314, 0.5411765 , 0.5882353 ]],\n",
       "   \n",
       "          [[0.21176471, 0.26666668, 0.4117647 ],\n",
       "           [0.21176471, 0.26666668, 0.4117647 ],\n",
       "           [0.21176471, 0.26666668, 0.4117647 ],\n",
       "           ...,\n",
       "           [0.41568628, 0.54901963, 0.59607846],\n",
       "           [0.4117647 , 0.54509807, 0.5921569 ],\n",
       "           [0.40784314, 0.5411765 , 0.5882353 ]],\n",
       "   \n",
       "          [[0.21176471, 0.26666668, 0.4117647 ],\n",
       "           [0.21176471, 0.26666668, 0.4117647 ],\n",
       "           [0.21176471, 0.26666668, 0.4117647 ],\n",
       "           ...,\n",
       "           [0.4117647 , 0.54509807, 0.5921569 ],\n",
       "           [0.4117647 , 0.54509807, 0.5921569 ],\n",
       "           [0.4117647 , 0.54509807, 0.5921569 ]],\n",
       "   \n",
       "          ...,\n",
       "   \n",
       "          [[0.16470589, 0.16862746, 0.10588235],\n",
       "           [0.05490196, 0.05882353, 0.        ],\n",
       "           [0.16470589, 0.16862746, 0.11372549],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        ],\n",
       "           [0.01568628, 0.01568628, 0.01568628],\n",
       "           [0.03137255, 0.03137255, 0.03137255]],\n",
       "   \n",
       "          [[0.22745098, 0.22352941, 0.15294118],\n",
       "           [0.12941177, 0.1254902 , 0.05490196],\n",
       "           [0.16470589, 0.15686275, 0.09803922],\n",
       "           ...,\n",
       "           [0.01176471, 0.01176471, 0.01176471],\n",
       "           [0.01568628, 0.01568628, 0.01568628],\n",
       "           [0.01568628, 0.01568628, 0.01568628]],\n",
       "   \n",
       "          [[0.21960784, 0.21568628, 0.14509805],\n",
       "           [0.29803923, 0.29411766, 0.22352941],\n",
       "           [0.25882354, 0.2509804 , 0.19215687],\n",
       "           ...,\n",
       "           [0.01568628, 0.01568628, 0.01568628],\n",
       "           [0.01568628, 0.01568628, 0.01568628],\n",
       "           [0.00392157, 0.00392157, 0.00392157]]], dtype=float32),\n",
       "   array([[[0.1254902 , 0.14117648, 0.2784314 ],\n",
       "           [0.1254902 , 0.14117648, 0.2784314 ],\n",
       "           [0.12941177, 0.14509805, 0.28235295],\n",
       "           ...,\n",
       "           [0.06666667, 0.06666667, 0.06666667],\n",
       "           [0.04705882, 0.04705882, 0.04705882],\n",
       "           [0.02352941, 0.02352941, 0.02352941]],\n",
       "   \n",
       "          [[0.12156863, 0.13725491, 0.27450982],\n",
       "           [0.12156863, 0.13725491, 0.27450982],\n",
       "           [0.1254902 , 0.14117648, 0.2784314 ],\n",
       "           ...,\n",
       "           [0.01176471, 0.01176471, 0.01176471],\n",
       "           [0.00392157, 0.00392157, 0.00392157],\n",
       "           [0.        , 0.        , 0.        ]],\n",
       "   \n",
       "          [[0.12156863, 0.13725491, 0.27450982],\n",
       "           [0.12156863, 0.13725491, 0.27450982],\n",
       "           [0.12156863, 0.13725491, 0.27450982],\n",
       "           ...,\n",
       "           [0.01960784, 0.01960784, 0.01960784],\n",
       "           [0.01960784, 0.01960784, 0.01960784],\n",
       "           [0.00392157, 0.00392157, 0.00392157]],\n",
       "   \n",
       "          ...,\n",
       "   \n",
       "          [[0.1764706 , 0.20392157, 0.17254902],\n",
       "           [0.1882353 , 0.21568628, 0.18431373],\n",
       "           [0.20392157, 0.23529412, 0.19215687],\n",
       "           ...,\n",
       "           [0.8862745 , 0.8666667 , 0.88235295],\n",
       "           [0.972549  , 0.9607843 , 0.9411765 ],\n",
       "           [0.9843137 , 0.972549  , 0.94509804]],\n",
       "   \n",
       "          [[0.22352941, 0.19215687, 0.18431373],\n",
       "           [0.23529412, 0.20392157, 0.19215687],\n",
       "           [0.24705882, 0.21568628, 0.20392157],\n",
       "           ...,\n",
       "           [0.81960785, 0.7764706 , 0.7529412 ],\n",
       "           [0.972549  , 0.9372549 , 0.8784314 ],\n",
       "           [1.        , 0.9607843 , 0.8901961 ]],\n",
       "   \n",
       "          [[0.27058825, 0.20784314, 0.21176471],\n",
       "           [0.2784314 , 0.21568628, 0.21960784],\n",
       "           [0.28627452, 0.22352941, 0.22352941],\n",
       "           ...,\n",
       "           [0.73333335, 0.68235296, 0.64705884],\n",
       "           [0.9098039 , 0.8509804 , 0.7764706 ],\n",
       "           [0.93333334, 0.8745098 , 0.78431374]]], dtype=float32)]),\n",
       " (201903061230, []),\n",
       " (201903061300, []),\n",
       " (201903061330, []),\n",
       " (201903061400, []),\n",
       " (201903061430, []),\n",
       " (201903061500, []),\n",
       " (201903061530, []),\n",
       " (201903061600, []),\n",
       " (201903061630, []),\n",
       " (201903061700, []),\n",
       " (201903061730, []),\n",
       " (201903061800, []),\n",
       " (201903061830, []),\n",
       " (201903061900, []),\n",
       " (201903061930, [])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phenocam_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40343385\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ds)):\n",
    "    if ds.data[i][0] == 'US-xDJ':\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Tuesday\n",
    "# I finished basic EC data loading, now I need to work on:\n",
    "# - MODIS image loading\n",
    "# - Phenocam loading\n",
    "# - collate function and general structure (dataclass for data delivery?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
